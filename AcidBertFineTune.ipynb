{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AcidBertFineTune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a22d12bd61c4dd7ba94c40b1deb4fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92a2be2ef888488b996e1388b028a89e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a743179fc66145a6949a9047ebd5e862",
              "IPY_MODEL_0e18eb593e7041b1b4b8b65d19fa2994",
              "IPY_MODEL_fba56981f7a246ceb6e53a4507b87ed2"
            ]
          }
        },
        "92a2be2ef888488b996e1388b028a89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a743179fc66145a6949a9047ebd5e862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a48debe8829f41fd91777083175ac1bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02a30627e60b473292cca2ab86fff734"
          }
        },
        "0e18eb593e7041b1b4b8b65d19fa2994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e10881221bc04cb48f361b154bdc5156",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abf8cef93b344eedb483ebb3aeec233a"
          }
        },
        "fba56981f7a246ceb6e53a4507b87ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78fd1109984f4e8b9fde5b466357bd56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:20&lt;00:00, 38.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a16290bfb4f4e62a097efa4709be251"
          }
        },
        "a48debe8829f41fd91777083175ac1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02a30627e60b473292cca2ab86fff734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e10881221bc04cb48f361b154bdc5156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abf8cef93b344eedb483ebb3aeec233a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78fd1109984f4e8b9fde5b466357bd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a16290bfb4f4e62a097efa4709be251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow\n",
        "%pip install numpy\n",
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o1m8ShUdQd-",
        "outputId": "4639943c-7d6f-4b43-ecc7-10f80c6fbf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 20.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qOFIJ9VTdWNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "yxb5nZ61dYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOf8MOspEs8K",
        "outputId": "cf5bf605-9666-41a4-9d2b-3f2ad5899eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set environment as googledrive to folder \"resource\"\n",
        "from google.colab import drive\n",
        "\n",
        "data_path =  \"/atis/\"\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = \"/content/drive/MyDrive/atis/\"\n",
        "\n",
        "except:\n",
        "    print(\"You are not working in Colab at the moment :(\")"
      ],
      "metadata": {
        "id": "bVi6vSIsE6ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23eecac3-7796-463a-ac4a-474bddbe3d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = [\"type\",\"text\",\"category\"]\n",
        "df_acid = pd.read_csv(\"drive/MyDrive/acidData/alldata.csv\",names=col_names, header=None)\n",
        "df_acid"
      ],
      "metadata": {
        "id": "KiH5s-lQdfdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "aa712e65-92f4-4964-b3bb-d708caf89638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2119b558-2b2d-4fc3-a33a-fc6d4660abe5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clinc150</td>\n",
              "      <td>in spanish, meet me tomorrow is said how</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clinc150</td>\n",
              "      <td>in french, how do i say, see you later</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clinc150</td>\n",
              "      <td>how do you say hello in japanese</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clinc150</td>\n",
              "      <td>how do i ask about the weather in chinese</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clinc150</td>\n",
              "      <td>how can i say cancel my order in french</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75533</th>\n",
              "      <td>xliuhw-bench</td>\n",
              "      <td>that's cool, musch appreciated, olly.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75534</th>\n",
              "      <td>xliuhw-bench</td>\n",
              "      <td>you are hero, appreciated.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75535</th>\n",
              "      <td>xliuhw-bench</td>\n",
              "      <td>thanks, that's nice.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75536</th>\n",
              "      <td>xliuhw-bench</td>\n",
              "      <td>that's cool, thank you so much.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75537</th>\n",
              "      <td>xliuhw-bench</td>\n",
              "      <td>appreciate your answers, olly.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75538 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2119b558-2b2d-4fc3-a33a-fc6d4660abe5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2119b558-2b2d-4fc3-a33a-fc6d4660abe5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2119b558-2b2d-4fc3-a33a-fc6d4660abe5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               type                                       text        category\n",
              "0          clinc150   in spanish, meet me tomorrow is said how       translate\n",
              "1          clinc150     in french, how do i say, see you later       translate\n",
              "2          clinc150           how do you say hello in japanese       translate\n",
              "3          clinc150  how do i ask about the weather in chinese       translate\n",
              "4          clinc150    how can i say cancel my order in french       translate\n",
              "...             ...                                        ...             ...\n",
              "75533  xliuhw-bench      that's cool, musch appreciated, olly.  general.praise\n",
              "75534  xliuhw-bench                 you are hero, appreciated.  general.praise\n",
              "75535  xliuhw-bench                       thanks, that's nice.  general.praise\n",
              "75536  xliuhw-bench            that's cool, thank you so much.  general.praise\n",
              "75537  xliuhw-bench             appreciate your answers, olly.  general.praise\n",
              "\n",
              "[75538 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acid[\"type\"].value_counts()"
      ],
      "metadata": {
        "id": "8XpeTKYddjiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de7d378-fa02-4207-cf6b-5963cb8f261d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "xliuhw-bench            25716\n",
              "clinc150                22500\n",
              "snips-bench-2017cie     13784\n",
              "polyai-tsd-banking77    13081\n",
              "sebis-eval-chatbot        206\n",
              "sebis-eval-askubuntu      162\n",
              "sebis-eval-webapps         89\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_counts = df_acid[\"category\"].value_counts()\n",
        "df_counts = df_counts.to_dict()\n",
        "len(df_counts)\n",
        "#total 315\n"
      ],
      "metadata": {
        "id": "PoL2e8czdniQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145d16c2-682a-42ac-8be4-2783dc408613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "315"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acid.drop('type', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "HV5q12vGdoKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_acid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_VR9u8oydoMI",
        "outputId": "a2985d5d-2d00-4743-84a4-958d81d9432e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc73d1cc-4e6d-4354-b2b4-790e222b3c2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in spanish, meet me tomorrow is said how</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in french, how do i say, see you later</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how do you say hello in japanese</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how do i ask about the weather in chinese</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how can i say cancel my order in french</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75533</th>\n",
              "      <td>that's cool, musch appreciated, olly.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75534</th>\n",
              "      <td>you are hero, appreciated.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75535</th>\n",
              "      <td>thanks, that's nice.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75536</th>\n",
              "      <td>that's cool, thank you so much.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75537</th>\n",
              "      <td>appreciate your answers, olly.</td>\n",
              "      <td>general.praise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75538 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc73d1cc-4e6d-4354-b2b4-790e222b3c2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc73d1cc-4e6d-4354-b2b4-790e222b3c2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc73d1cc-4e6d-4354-b2b4-790e222b3c2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            text        category\n",
              "0       in spanish, meet me tomorrow is said how       translate\n",
              "1         in french, how do i say, see you later       translate\n",
              "2               how do you say hello in japanese       translate\n",
              "3      how do i ask about the weather in chinese       translate\n",
              "4        how can i say cancel my order in french       translate\n",
              "...                                          ...             ...\n",
              "75533      that's cool, musch appreciated, olly.  general.praise\n",
              "75534                 you are hero, appreciated.  general.praise\n",
              "75535                       thanks, that's nice.  general.praise\n",
              "75536            that's cool, thank you so much.  general.praise\n",
              "75537             appreciate your answers, olly.  general.praise\n",
              "\n",
              "[75538 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acid_labels = LabelEncoder().fit_transform(df_acid[\"category\"])\n",
        "df_acid_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fnx4h18Q_-B",
        "outputId": "39af2c5b-8189-476b-acaf-c92accf65dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([282, 282, 282, ..., 133, 133, 133])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acid[\"category\"] = df_acid_labels\n",
        "df_acid = df_acid.dropna()\n",
        "df_acid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BSxpGBLgROQ-",
        "outputId": "9503abb5-135a-4edb-c923-e9ccf7e65a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56aabc27-90d5-40a8-a4fa-1ed59091da88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in spanish, meet me tomorrow is said how</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in french, how do i say, see you later</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how do you say hello in japanese</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how do i ask about the weather in chinese</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how can i say cancel my order in french</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75533</th>\n",
              "      <td>that's cool, musch appreciated, olly.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75534</th>\n",
              "      <td>you are hero, appreciated.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75535</th>\n",
              "      <td>thanks, that's nice.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75536</th>\n",
              "      <td>that's cool, thank you so much.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75537</th>\n",
              "      <td>appreciate your answers, olly.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75429 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56aabc27-90d5-40a8-a4fa-1ed59091da88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56aabc27-90d5-40a8-a4fa-1ed59091da88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56aabc27-90d5-40a8-a4fa-1ed59091da88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            text  category\n",
              "0       in spanish, meet me tomorrow is said how       282\n",
              "1         in french, how do i say, see you later       282\n",
              "2               how do you say hello in japanese       282\n",
              "3      how do i ask about the weather in chinese       282\n",
              "4        how can i say cancel my order in french       282\n",
              "...                                          ...       ...\n",
              "75533      that's cool, musch appreciated, olly.       133\n",
              "75534                 you are hero, appreciated.       133\n",
              "75535                       thanks, that's nice.       133\n",
              "75536            that's cool, thank you so much.       133\n",
              "75537             appreciate your answers, olly.       133\n",
              "\n",
              "[75429 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KqfttoVUTwMY",
        "outputId": "c8fb1601-1108-4efa-b420-ac26bc49d747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8fd62615-2240-4c40-9e21-8e8f4852adf4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in spanish, meet me tomorrow is said how</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in french, how do i say, see you later</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how do you say hello in japanese</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how do i ask about the weather in chinese</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how can i say cancel my order in french</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75533</th>\n",
              "      <td>that's cool, musch appreciated, olly.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75534</th>\n",
              "      <td>you are hero, appreciated.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75535</th>\n",
              "      <td>thanks, that's nice.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75536</th>\n",
              "      <td>that's cool, thank you so much.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75537</th>\n",
              "      <td>appreciate your answers, olly.</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75429 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fd62615-2240-4c40-9e21-8e8f4852adf4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fd62615-2240-4c40-9e21-8e8f4852adf4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fd62615-2240-4c40-9e21-8e8f4852adf4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            text  category\n",
              "0       in spanish, meet me tomorrow is said how       282\n",
              "1         in french, how do i say, see you later       282\n",
              "2               how do you say hello in japanese       282\n",
              "3      how do i ask about the weather in chinese       282\n",
              "4        how can i say cancel my order in french       282\n",
              "...                                          ...       ...\n",
              "75533      that's cool, musch appreciated, olly.       133\n",
              "75534                 you are hero, appreciated.       133\n",
              "75535                       thanks, that's nice.       133\n",
              "75536            that's cool, thank you so much.       133\n",
              "75537             appreciate your answers, olly.       133\n",
              "\n",
              "[75429 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_acid, test_acid = train_test_split(df_acid, test_size=0.2)  #shuffled"
      ],
      "metadata": {
        "id": "Krs8sB9OPs9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = train_acid[\"text\"].tolist()\n",
        "train_labels = train_acid[\"category\"].tolist()\n",
        "\n",
        "test_texts = test_acid[\"text\"].tolist()\n",
        "test_labels = test_acid[\"category\"].tolist()"
      ],
      "metadata": {
        "id": "x9NQ3KLZPy4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_categories = len(set(train_labels))\n",
        "number_of_categories"
      ],
      "metadata": {
        "id": "ylvJlw3Ddx6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bed3ec-a2e6-4c76-e7ce-36f2df786445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "316"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "sentences = train_texts\n",
        "max_len = 250\n"
      ],
      "metadata": {
        "id": "Ek1nuW6XEGQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qu5d8H1TSlZ",
        "outputId": "13aba4c5-9e91-41f5-b5c9-50dc1d1f4aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60343"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ut0cfnTkE8",
        "outputId": "a1ba9316-4118-472b-b962-6a30f0773b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15086"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in train_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                    \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_len,      \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(train_labels)\n",
        "\n",
        "print('Original: ', train_texts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "Txl75gtD7vaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0210d0b-6ba1-4c28-faa5-29b87fbe4517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Alexa, today I had a lunch with my longtime sweetheart. Play me a nice song to the mood.\n",
            "Token IDs: tensor([  101, 24969,  1010,  2651,  1045,  2018,  1037,  6265,  2007,  2026,\n",
            "        11155, 12074,  1012,  2377,  2033,  1037,  3835,  2299,  2000,  1996,\n",
            "         6888,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "number_of_categories = len(set(train_labels))\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels = number_of_categories, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "9cj49nJhH05t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8a22d12bd61c4dd7ba94c40b1deb4fc9",
            "92a2be2ef888488b996e1388b028a89e",
            "a743179fc66145a6949a9047ebd5e862",
            "0e18eb593e7041b1b4b8b65d19fa2994",
            "fba56981f7a246ceb6e53a4507b87ed2",
            "a48debe8829f41fd91777083175ac1bf",
            "02a30627e60b473292cca2ab86fff734",
            "e10881221bc04cb48f361b154bdc5156",
            "abf8cef93b344eedb483ebb3aeec233a",
            "78fd1109984f4e8b9fde5b466357bd56",
            "1a16290bfb4f4e62a097efa4709be251"
          ]
        },
        "outputId": "908d1d9a-cf0c-44a0-e3c5-008d6c79d29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a22d12bd61c4dd7ba94c40b1deb4fc9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=316, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5,\n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "\n"
      ],
      "metadata": {
        "id": "SY2GflQuH1Co",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4b5f1d-001f-4f75-f407-cb60b99739cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 1903\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        output = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels)\n",
        "        loss = output['loss']\n",
        "        logits = output['logits']\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "metadata": {
        "id": "BEPyBem2IBgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a49047-ee94-4a3d-e330-489610521446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Batch    10  of  1,886.    Elapsed: 0:00:25.\n",
            "Batch    20  of  1,886.    Elapsed: 0:00:50.\n",
            "Batch    30  of  1,886.    Elapsed: 0:01:15.\n",
            "Batch    40  of  1,886.    Elapsed: 0:01:40.\n",
            "Batch    50  of  1,886.    Elapsed: 0:02:05.\n",
            "Batch    60  of  1,886.    Elapsed: 0:02:30.\n",
            "Batch    70  of  1,886.    Elapsed: 0:02:55.\n",
            "Batch    80  of  1,886.    Elapsed: 0:03:20.\n",
            "Batch    90  of  1,886.    Elapsed: 0:03:45.\n",
            "Batch   100  of  1,886.    Elapsed: 0:04:10.\n",
            "Batch   110  of  1,886.    Elapsed: 0:04:35.\n",
            "Batch   120  of  1,886.    Elapsed: 0:05:00.\n",
            "Batch   130  of  1,886.    Elapsed: 0:05:25.\n",
            "Batch   140  of  1,886.    Elapsed: 0:05:50.\n",
            "Batch   150  of  1,886.    Elapsed: 0:06:15.\n",
            "Batch   160  of  1,886.    Elapsed: 0:06:40.\n",
            "Batch   170  of  1,886.    Elapsed: 0:07:05.\n",
            "Batch   180  of  1,886.    Elapsed: 0:07:29.\n",
            "Batch   190  of  1,886.    Elapsed: 0:07:54.\n",
            "Batch   200  of  1,886.    Elapsed: 0:08:19.\n",
            "Batch   210  of  1,886.    Elapsed: 0:08:44.\n",
            "Batch   220  of  1,886.    Elapsed: 0:09:09.\n",
            "Batch   230  of  1,886.    Elapsed: 0:09:34.\n",
            "Batch   240  of  1,886.    Elapsed: 0:09:59.\n",
            "Batch   250  of  1,886.    Elapsed: 0:10:24.\n",
            "Batch   260  of  1,886.    Elapsed: 0:10:49.\n",
            "Batch   270  of  1,886.    Elapsed: 0:11:14.\n",
            "Batch   280  of  1,886.    Elapsed: 0:11:39.\n",
            "Batch   290  of  1,886.    Elapsed: 0:12:04.\n",
            "Batch   300  of  1,886.    Elapsed: 0:12:29.\n",
            "Batch   310  of  1,886.    Elapsed: 0:12:54.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qatDGRDnIDYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d7e26b78-e318-48b7-ea71-9cdab15cf14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = test_texts\n",
        "test_labels = test_labels\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in test_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                     \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = max_len,          \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',   \n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "kwadWigCIbVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b7bb90-845e-4f2d-ff3a-4263a0e68ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction started on test data')\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Prediction completed')\n",
        "\n",
        "prediction_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  prediction_set.append(pred_labels_i)\n",
        "\n",
        "prediction_scores = [item for sublist in prediction_set for item in sublist]"
      ],
      "metadata": {
        "id": "FOkHtkfjIjCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986be6a7-70a2-436c-93e4-30425061af49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction started on test data\n",
            "Prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
        "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
        "recall = recall_score(test_labels, prediction_scores, average='macro')\n",
        "\n",
        "print(\"F-Score: \", f_score)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)\n"
      ],
      "metadata": {
        "id": "LTQEnHsnIji2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2d9d55-08a1-4a13-8b7e-11318090a37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score:  0.9304128464585665\n",
            "Recall:  0.930194805194805\n",
            "Precision:  0.9332023654036132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_labels_ = banking_train_labels\n",
        "train_labels_encodded = LabelEncoder().fit_transform(train_labels_)\n"
      ],
      "metadata": {
        "id": "007G4qUPLyMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(zip( train_labels_encodded,train_labels_))\n",
        "print(dictionary)"
      ],
      "metadata": {
        "id": "RjMBDE6KMNZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f89179-cc2c-40ab-932d-ad51a3585f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{12: 'card_arrival', 14: 'card_linking', 33: 'exchange_rate', 18: 'card_payment_wrong_exchange_rate', 35: 'extra_charge_on_statement', 47: 'pending_cash_withdrawal', 37: 'fiat_currency_support', 13: 'card_delivery_estimate', 5: 'automatic_top_up', 15: 'card_not_working', 34: 'exchange_via_app', 42: 'lost_or_stolen_card', 2: 'age_limit', 50: 'pin_blocked', 24: 'contactless_not_working', 56: 'top_up_by_bank_transfer_charge', 48: 'pending_top_up', 9: 'cancel_transfer', 60: 'top_up_limits', 75: 'wrong_amount_of_cash_received', 16: 'card_payment_fee_charged', 66: 'transfer_not_received_by_recipient', 54: 'supported_cards_and_currencies', 41: 'getting_virtual_card', 11: 'card_acceptance', 61: 'top_up_reverted', 7: 'balance_not_updated_after_cheque_or_cash_deposit', 17: 'card_payment_not_recognised', 31: 'edit_personal_details', 74: 'why_verify_identity', 68: 'unable_to_verify_identity', 39: 'get_physical_card', 73: 'visa_or_mastercard', 62: 'topping_up_by_card', 30: 'disposable_card_limits', 23: 'compromised_card', 4: 'atm_support', 29: 'direct_debit_payment_not_recognised', 45: 'passcode_forgotten', 27: 'declined_cash_withdrawal', 46: 'pending_card_payment', 43: 'lost_or_stolen_phone', 52: 'request_refund', 28: 'declined_transfer', 0: 'Refund_not_showing_up', 26: 'declined_card_payment', 49: 'pending_transfer', 55: 'terminate_account', 19: 'card_swallowed', 63: 'transaction_charged_twice', 70: 'verify_source_of_funds', 67: 'transfer_timing', 53: 'reverted_card_payment?', 22: 'change_pin', 8: 'beneficiary_not_allowed', 64: 'transfer_fee_charged', 51: 'receiving_money', 36: 'failed_transfer', 65: 'transfer_into_account', 71: 'verify_top_up', 40: 'getting_spare_card', 58: 'top_up_by_cash_or_cheque', 44: 'order_physical_card', 72: 'virtual_card_not_working', 76: 'wrong_exchange_rate_for_cash_withdrawal', 38: 'get_disposable_virtual_card', 59: 'top_up_failed', 6: 'balance_not_updated_after_bank_transfer', 21: 'cash_withdrawal_not_recognised', 32: 'exchange_charge', 57: 'top_up_by_card_charge', 1: 'activate_my_card', 20: 'cash_withdrawal_charge', 10: 'card_about_to_expire', 3: 'apple_pay_or_google_pay', 69: 'verify_my_identity', 25: 'country_support'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))\n",
        "report = report.rename(columns=dictionary)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "wxSpt6vhMsfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e75e38-6f00-45a6-a02c-a8fa7a217287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   0          1     2  ...  accuracy    macro avg  weighted avg\n",
            "precision   1.000000   1.000000   1.0  ...  0.930195     0.933202      0.933202\n",
            "recall      0.975000   0.975000   1.0  ...  0.930195     0.930195      0.930195\n",
            "f1-score    0.987342   0.987342   1.0  ...  0.930195     0.930413      0.930413\n",
            "support    40.000000  40.000000  40.0  ...  0.930195  3080.000000   3080.000000\n",
            "\n",
            "[4 rows x 80 columns]\n"
          ]
        }
      ]
    }
  ]
}